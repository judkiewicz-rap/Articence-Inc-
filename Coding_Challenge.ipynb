{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coding Challenge.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPx4a6tHZ1UL",
        "colab_type": "code",
        "outputId": "ff91cec4-ead4-4f96-b79d-7754bf280928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHn0UV9OhoPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers as ppb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn, optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYtYgQGxTejM",
        "colab_type": "code",
        "outputId": "bd9204d7-d294-4f33-9eae-a889e38d8f2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1bFYRBWjAqXFxrRnA6XGqRY2ffh6gsAgG'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('IMDB Dataset.csv') \n",
        "data = pd.read_csv('IMDB Dataset.csv')\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>length of text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Match 1: Tag Team Table Match Bubba Ray and Sp...</td>\n",
              "      <td>13704</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>There's a sign on The Lost Highway that says:&lt;...</td>\n",
              "      <td>12988</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Some spoilers included:)&lt;br /&gt;&lt;br /&gt;Although,...</td>\n",
              "      <td>12930</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Back in the mid/late 80s, an OAV anime by titl...</td>\n",
              "      <td>12129</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>**Attention Spoilers**&lt;br /&gt;&lt;br /&gt;First of all...</td>\n",
              "      <td>10363</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  length of text sentiment\n",
              "0  Match 1: Tag Team Table Match Bubba Ray and Sp...           13704  positive\n",
              "1  There's a sign on The Lost Highway that says:<...           12988  positive\n",
              "2  (Some spoilers included:)<br /><br />Although,...           12930  positive\n",
              "3  Back in the mid/late 80s, an OAV anime by titl...           12129  positive\n",
              "4  **Attention Spoilers**<br /><br />First of all...           10363  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omeiGCiNRJoA",
        "colab_type": "code",
        "outputId": "45ed4a41-6f55-4a15-be39-b279635c793d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haOJdJmmU1PT",
        "colab_type": "code",
        "outputId": "3aa0f80b-d81c-4d12-d7b7-b447c8ee446c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "data['sentiment'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    25000\n",
              "negative    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96He1_Fh6ir8",
        "colab_type": "text"
      },
      "source": [
        "We're gona tranform the sentiment into a dummy variable so the analysis will be easier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d99Gw0WPt-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['sentiment']=data['sentiment'].apply(lambda row: np.where(row=='positive',1,0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T3gcjGMQByt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3404f984-f197-45a1-b2a9-358fac1e3226"
      },
      "source": [
        "data['sentiment'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    25000\n",
              "0    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb5r3jMBU9wC",
        "colab_type": "text"
      },
      "source": [
        "The dataset is balanced, we don't need to modify it.\n",
        "We split it so that we can cross-validate our resutls."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXjJ6JkH7eCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train, df_test = train_test_split(data, test_size=0.1)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9esCr2QB63pt",
        "colab_type": "text"
      },
      "source": [
        "We need to preprocess the data by tokenizing it, so that it can bu understood by our model. To do that, we're gonna use the pre-trained Bert Tranformer from the transformer librairy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZnsfJkhddzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AJivPmS7pt1",
        "colab_type": "text"
      },
      "source": [
        "After that, we need to create a Data Loader to use the resulting dataset of our pre-processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfd1srWICpsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df['review'].to_numpy(),\n",
        "    targets=df['sentiment'].to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnkKVlRA8BD5",
        "colab_type": "text"
      },
      "source": [
        "The max length is the length of the tokenizez sentence. Normally, Bert accept a max length of 512. However, because of memory issues, we are only using 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tM6sKnUD2Fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "max_len=200\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, max_len, batch_size)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, max_len, batch_size)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, max_len, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VNpOh-281pS",
        "colab_type": "text"
      },
      "source": [
        "Bert is already pre-trained, thus we can use transfer learning so get some results. In this case, we're adding a dropout layer, and a fully-connected with two neurons for our output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dCpn5ZoC5yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = ppb.BertModel.from_pretrained('bert-base-uncased')\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEPkr7EOM9Kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg0vbNJpC6_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SentimentClassifier(2)\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ondbXvP39awG",
        "colab_type": "text"
      },
      "source": [
        "We're gonna try our model on a test batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC6iwj5eQUGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = next(iter(train_data_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKkj4TukMqmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b365c461-cb7b-45a7-949f-7a28fb321df2"
      },
      "source": [
        "input_ids = test['input_ids'].to(device)\n",
        "attention_mask = test['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 200])\n",
            "torch.Size([32, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrsF3VpRDS8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "5552c35f-31e9-4a6f-cb66-aff090870338"
      },
      "source": [
        "nn.functional.softmax(model(input_ids, attention_mask), dim=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.7979e-03, 9.9220e-01],\n",
              "        [3.1158e-02, 9.6884e-01],\n",
              "        [9.9909e-01, 9.1435e-04],\n",
              "        [8.4817e-03, 9.9152e-01],\n",
              "        [9.9760e-01, 2.4016e-03],\n",
              "        [9.9746e-01, 2.5438e-03],\n",
              "        [6.9988e-01, 3.0012e-01],\n",
              "        [9.9321e-01, 6.7899e-03],\n",
              "        [9.9776e-01, 2.2382e-03],\n",
              "        [9.9863e-01, 1.3716e-03],\n",
              "        [2.8701e-03, 9.9713e-01],\n",
              "        [8.4338e-01, 1.5662e-01],\n",
              "        [9.8252e-01, 1.7477e-02],\n",
              "        [9.9950e-01, 5.0212e-04],\n",
              "        [9.8962e-01, 1.0382e-02],\n",
              "        [1.6586e-03, 9.9834e-01],\n",
              "        [9.9681e-01, 3.1917e-03],\n",
              "        [9.9908e-01, 9.2120e-04],\n",
              "        [9.7856e-01, 2.1435e-02],\n",
              "        [9.9893e-01, 1.0741e-03],\n",
              "        [7.4931e-03, 9.9251e-01],\n",
              "        [9.9921e-01, 7.9241e-04],\n",
              "        [1.6838e-03, 9.9832e-01],\n",
              "        [1.1401e-02, 9.8860e-01],\n",
              "        [3.3195e-03, 9.9668e-01],\n",
              "        [1.4358e-02, 9.8564e-01],\n",
              "        [9.4923e-01, 5.0769e-02],\n",
              "        [9.9863e-01, 1.3750e-03],\n",
              "        [8.3647e-03, 9.9164e-01],\n",
              "        [5.7474e-03, 9.9425e-01],\n",
              "        [2.7962e-01, 7.2038e-01],\n",
              "        [9.9314e-01, 6.8569e-03]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7vd8kegQVz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3c633346-8d56-411f-c68e-024f2d1995dd"
      },
      "source": [
        "test['targets']"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "        1, 1, 0, 0, 1, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQEsHPQk9X2P",
        "colab_type": "text"
      },
      "source": [
        "We can see that on a batch test, the results seem coherent. We will now try to train the pre-trained model, to get the best results possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMZkKfOwDTiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 2\n",
        "\n",
        "optimizer = ppb.AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = ppb.get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYteMQNuDWMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt7lbRkQD71v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYKzsyk7D9n8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "e4c7887a-f839-4020-f66a-4d3e4299b8d9"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "----------\n",
            "Train loss 0.26523301232534685 accuracy 0.8909555555555556\n",
            "Val   loss 0.2094722317083727 accuracy 0.9184\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "Train loss 0.13220838201381185 accuracy 0.9544444444444445\n",
            "Val   loss 0.2571580213600699 accuracy 0.9128000000000001\n",
            "\n",
            "CPU times: user 55min 43s, sys: 36min 36s, total: 1h 32min 20s\n",
            "Wall time: 1h 33min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwzaeTNC9uj5",
        "colab_type": "text"
      },
      "source": [
        "The results are actually pretty good on the train and the validation set. Let's see the performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3q67Z0JQtLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dd0dde37-7cae-4bd9-9442-5a09c5385d49"
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.906"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6WKWKNB-AHj",
        "colab_type": "text"
      },
      "source": [
        "The accuracy on the test set is almost the same, we don't have an overfitting problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huFrraY1-EQu",
        "colab_type": "text"
      },
      "source": [
        "If we wanted to imporve our model, we should firstly set the max_length at 512. However, most of the sentences are longer that that. therefore, we could separate the reviews into parts, and addind a layer to our model to take recombine the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6SRre95-inL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}